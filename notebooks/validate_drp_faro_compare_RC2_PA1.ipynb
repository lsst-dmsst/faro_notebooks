{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of results from validate_drp and SPORK on the same dataset.\n",
    "\n",
    "In particular, this comparison is run on HSC RC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.table import hstack, Column\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "import lsst.verify\n",
    "import lsst.geom as geom\n",
    "import lsst.daf.persistence as dafPersist\n",
    "from lsst.verify.gen2tasks import register, MetricsControllerTask\n",
    "from lsst.verify.tasks import MetricTask\n",
    "import lsst.daf.butler as dafButler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output from a run of validate_drp:\n",
    "validate_job_g9813 = '/datasets/hsc/repo/rerun/RC/w_2020_34/DM-26441/validateDrp/matchedVisitMetrics/9813/HSC-G/matchedVisit_HSC-G.json'\n",
    "validate_job_r9813 = '/datasets/hsc/repo/rerun/RC/w_2020_34/DM-26441/validateDrp/matchedVisitMetrics/9813/HSC-R/matchedVisit_HSC-R.json'\n",
    "validate_job_i9813 = '/datasets/hsc/repo/rerun/RC/w_2020_34/DM-26441/validateDrp/matchedVisitMetrics/9813/HSC-I/matchedVisit_HSC-I.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validate_drp results come from executing something similar to the following commands (shown here running on the v20_0_0_rc1 processing of the RC2 dataset):\n",
    "\n",
    "matchedVisitMetrics.py /datasets/hsc/repo/rerun/RC/v20_0_0_rc1/DM-25349 --output /project/jcarlin/mvm_w_25 --config instrumentName='HSC' datasetName='HSC-RC2' --id tract=9615 filter='HSC-G^HSC-R^HSC-I'\n",
    "\n",
    "matchedVisitMetrics.py /datasets/hsc/repo/rerun/RC/v20_0_0_rc1/DM-25349 --output /project/jcarlin/mvm_w_25/9813 --config instrumentName='HSC' datasetName='HSC-RC2' --id tract=9813 filter='HSC-G^HSC-R^HSC-I'\n",
    "\n",
    "matchedVisitMetrics.py /datasets/hsc/repo/rerun/RC/v20_0_0_rc1/DM-25349 --output /project/jcarlin/mvm_w_25/9697 --config instrumentName='HSC' datasetName='HSC-RC2' --id tract=9697 filter='HSC-G^HSC-R^HSC-I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the .json saved by each validate_drp run:\n",
    "with open(validate_job_g9813) as f:\n",
    "    job_g9813 = lsst.verify.Job.deserialize(**json.load(f))\n",
    "with open(validate_job_r9813) as f:\n",
    "    job_r9813 = lsst.verify.Job.deserialize(**json.load(f))\n",
    "with open(validate_job_i9813) as f:\n",
    "    job_i9813 = lsst.verify.Job.deserialize(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a metric report in the notebook (use \"spec_tags\" to specify design, stretch, or minimum req level):\n",
    "job_g9813.report(spec_tags=['design']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the measurements from the JSON:\n",
    "meas_g9813 = job_g9813.measurements.json\n",
    "meas_r9813 = job_r9813.measurements.json\n",
    "meas_i9813 = job_i9813.measurements.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the measurements into arrays:\n",
    "\n",
    "gen2_names_g9813 = []\n",
    "gen2_vals_g9813 = []\n",
    "gen2_units_g9813 = []\n",
    "\n",
    "for met in meas_g9813:\n",
    "    # print(met['metric'], met['value'], met['unit'])\n",
    "    gen2_names_g9813.append(met['metric'])\n",
    "    gen2_vals_g9813.append(met['value'])\n",
    "    gen2_units_g9813.append(met['unit'])\n",
    "    \n",
    "gen2_names_r9813 = []\n",
    "gen2_vals_r9813 = []\n",
    "gen2_units_r9813 = []\n",
    "\n",
    "for met in meas_r9813:\n",
    "    # print(met['metric'], met['value'], met['unit'])\n",
    "    gen2_names_r9813.append(met['metric'])\n",
    "    gen2_vals_r9813.append(met['value'])\n",
    "    gen2_units_r9813.append(met['unit'])\n",
    "    \n",
    "gen2_names_i9813 = []\n",
    "gen2_vals_i9813 = []\n",
    "gen2_units_i9813 = []\n",
    "\n",
    "for met in meas_i9813:\n",
    "    # print(met['metric'], met['value'], met['unit'])\n",
    "    gen2_names_i9813.append(met['metric'])\n",
    "    gen2_vals_i9813.append(met['value'])\n",
    "    gen2_units_i9813.append(met['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the arrays into astropy tables:\n",
    "tab_gen2_g9813 = Table([gen2_names_g9813, gen2_vals_g9813, gen2_units_g9813], names=['metric', 'value', 'units'], dtype=(str, 'f2', str))\n",
    "tab_gen2_r9813 = Table([gen2_names_r9813, gen2_vals_r9813, gen2_units_r9813], names=['metric', 'value', 'units'], dtype=(str, 'f2', str))\n",
    "tab_gen2_i9813 = Table([gen2_names_i9813, gen2_vals_i9813, gen2_units_i9813], names=['metric', 'value', 'units'], dtype=(str, 'f2', str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now get the Gen 3 butler results from running SPORK on RC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/project/hsc/gen3repo/rc2w34_ssw36/'\n",
    "config = os.path.join(repo,'butler.yaml')\n",
    "try: butler_gen3 = dafButler.Butler(config=config)\n",
    "except ValueError as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = butler_gen3.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what collections are in the repo:\n",
    "for c in registry.queryCollections():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what dataset types are (potentially) available:\n",
    "dstypes = []\n",
    "for x in registry.queryDatasetTypes():\n",
    "    print(x)\n",
    "    dstypes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dstypes:\n",
    "    if 'match' in d.name:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the names of the metrics we plan to extract from the repo:\n",
    "metricnames = ['PA1', 'PA2_design_gri', 'PF1_design_gri', 'AM1', 'AM2', 'AM3',\\\n",
    "               'AD1_design', 'AD2_design', 'AD3_design', 'AF1_design', 'AF2_design',\\\n",
    "               'AF3_design', 'TE1', 'TE2', 'AB1']\n",
    "#metricnames = ['PA1', 'PA2_design_gri', 'PF1_design_gri', 'AM1', 'AM2', 'AM3', 'AD1_design', 'AF1_design',\n",
    "#               'AD2_design', 'AF2_design', 'AD3_design', 'AF3_design', 'TE1', 'TE2', 'AB1_design']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = 'kbechtol/svv_9813_gri_matched'\n",
    "#collectionName = 'jcarlin/t9813_HSC-R_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_meas(collectionName, filt, tract, metrics):\n",
    "    \n",
    "    metric_agg_vals = []\n",
    "    metric_unit = []\n",
    "    metric_filter = []\n",
    "    metric_name = []\n",
    "    metric_ids = []\n",
    "    metric_meas = []\n",
    "\n",
    "    did={'tract':str(tract), 'abstract_filter':filt, 'instrument':'HSC', 'skymap':'hsc_rings_v1'}\n",
    "\n",
    "    for metric in metrics:\n",
    "        dataset = f\"metricvalue_summary_validate_drp_{metric}\"\n",
    "#        dataset = f\"metricvalue_summary_validate_drp_{metric}\"\n",
    "        query = registry.queryDatasets(datasetType=dataset, collections=[collectionName], dataId=did)\n",
    "        for meas in query:            \n",
    "            metric_tmp = butler_gen3.get(meas, collections=[collectionName])\n",
    "            metric_agg_vals.append(metric_tmp.quantity.value)\n",
    "            metric_unit.append(metric_tmp.quantity.unit)\n",
    "            metric_name.append(metric)\n",
    "            metric_ids.append(meas)\n",
    "            metric_meas.append(metric_tmp)\n",
    "            metric_filter.append(meas.dataId['abstract_filter'])\n",
    "    \n",
    "    tab_metrics = Table([metric_name, metric_unit, metric_filter, metric_agg_vals], \n",
    "                        names=('metric', 'unit', 'filter', str(tract)+'_gen3'), dtype=(str, str, str, 'f2'))\n",
    "        \n",
    "    return(tab_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1 = \"metricvalue_summary_validate_drp_PA1\"\n",
    "#dataset2 = \"metricvalue_Mean_validate_drp_PA1\"\n",
    "#dataset3 = \"metricvalue_validate_drp_PA1\"\n",
    "dataset3 = \"matchedCatalog\"\n",
    "did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':59}\n",
    "#metric_tmp1 = butler_gen3.get(dataset1, dataId=did, collections=[collectionName])\n",
    "#metric_tmp2 = butler_gen3.get(dataset2, dataId=did, collections=[collectionName])\n",
    "metric_tmp3 = butler_gen3.get(dataset3, dataId=did, collections=[collectionName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metric_tmp1, metric_tmp2, metric_tmp3)\n",
    "#print(did)\n",
    "len(set(metric_tmp3['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for s in metric_tmp3.schema:\n",
    "#    if 'flag' in s.field.getName():\n",
    "#        print(s.field.getName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract astropy tables of the metric values by calling the function defined above:\n",
    "tab_gen3_g9813 = get_metric_meas(collectionName, 'g', 9813, metricnames)\n",
    "tab_gen3_r9813 = get_metric_meas(collectionName, 'r', 9813, metricnames)\n",
    "tab_gen3_i9813 = get_metric_meas(collectionName, 'i', 9813, metricnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_gen3_r9813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the names of the metrics, picking out the corresponding measurements from Gen2 and Gen3 (and possibly from tracts/filters separately), compiling them into a table together. (Later, we may want to add in the specs?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_metrics_g9813 = tab_gen3_g9813.copy()\n",
    "matchcol=np.zeros(len(tab_metrics_g9813['9813_gen3']))\n",
    "\n",
    "for i in range(len(tab_metrics_g9813['metric'])):\n",
    "    name = tab_metrics_g9813['metric'][i]\n",
    "    find_in_tab2 = np.where(np.char.find(tab_gen2_g9813['metric'], name) >= 0)\n",
    "\n",
    "    if np.size(find_in_tab2) > 0:\n",
    "        matchcol[i] = tab_gen2_g9813['value'][find_in_tab2[0]]\n",
    "    else:\n",
    "        matchcol[i] = np.nan\n",
    "    \n",
    "tab_metrics_g9813_all = hstack([tab_metrics_g9813, Column(matchcol, name='9813_gen2', dtype='f2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_metrics_r9813 = tab_gen3_r9813.copy()\n",
    "matchcol=np.zeros(len(tab_metrics_r9813['9813_gen3']))\n",
    "\n",
    "for i in range(len(tab_metrics_r9813['metric'])):\n",
    "    name = tab_metrics_r9813['metric'][i]\n",
    "    find_in_tab2 = np.where(np.char.find(tab_gen2_r9813['metric'], name) >= 0)\n",
    "\n",
    "    if np.size(find_in_tab2) > 0:\n",
    "        matchcol[i] = tab_gen2_r9813['value'][find_in_tab2[0]]\n",
    "    else:\n",
    "        matchcol[i] = np.nan\n",
    "    \n",
    "tab_metrics_r9813_all = hstack([tab_metrics_r9813, Column(matchcol, name='9813_gen2', dtype='f2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_metrics_i9813 = tab_gen3_i9813.copy()\n",
    "matchcol=np.zeros(len(tab_metrics_i9813['9813_gen3']))\n",
    "\n",
    "for i in range(len(tab_metrics_i9813['metric'])):\n",
    "    name = tab_metrics_i9813['metric'][i]\n",
    "    find_in_tab2 = np.where(np.char.find(tab_gen2_i9813['metric'], name) >= 0)\n",
    "\n",
    "    if np.size(find_in_tab2) > 0:\n",
    "        matchcol[i] = tab_gen2_i9813['value'][find_in_tab2[0]]\n",
    "    else:\n",
    "        matchcol[i] = np.nan\n",
    "    \n",
    "tab_metrics_i9813_all = hstack([tab_metrics_i9813, Column(matchcol, name='9813_gen2', dtype='f2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them all into a single table:\n",
    "tab_gr_tmp = hstack([tab_metrics_g9813_all, tab_metrics_r9813_all['filter','9813_gen3', '9813_gen2']])\n",
    "tab_metrics_9813_all = hstack([tab_gr_tmp, tab_metrics_i9813_all['filter','9813_gen3', '9813_gen2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_metrics_9813_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a Latex table\n",
    "#tab_metrics_9813_all.write('compare_metrics_gen2and3_tract9813_RC2.tex', format='ascii.latex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the metric measurements per patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = registry.queryDataIds('patch',\n",
    "                                      dataId={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1'},\n",
    "                                      collections=[collectionName],datasets='metricvalue_summary_validate_drp_PA1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_tmp = []\n",
    "for d in dimensions:\n",
    "    patch_tmp.append(d['patch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = np.unique(patch_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':59}\n",
    "sm = butler_gen3.get('deepCoadd_skyMap', collections=['RC2/w_2020_34/DM-26441/remainder'],dataId=did)\n",
    "tract_info = sm.generateTract(9813)\n",
    "wcs = tract_info.getWcs()\n",
    "\n",
    "patchlist = []\n",
    "for patch in tract_info:\n",
    "    # print(patch)\n",
    "    patchlist.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Warning - this takes a long time to run!\n",
    "\n",
    "metric_agg_vals = np.zeros((len(patchlist),len(metricnames)))\n",
    "metric_agg_vals[:] = np.nan\n",
    "#metric_agg_vals = []\n",
    "metric_patch = []\n",
    "metric_ra = []\n",
    "metric_dec = []\n",
    "\n",
    "# For some reason patch 0, 8, 9, 63, 72 don't exist, so I had to skip them. Also note that butler_gen3.datasetExists fails on\n",
    "#   these patches, so I can't even use that to check for existence. Instead use try/except:\n",
    "for pch in patchlist:\n",
    "    p = tract_info.getSequentialPatchIndex(pch)\n",
    "    metric_patch.append(p)\n",
    "#    if p not in [8, 9, 63, 72]:\n",
    "    did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':p}\n",
    "    try:\n",
    "        coadd = butler_gen3.get('deepCoadd_calexp', collections=['RC2/w_2020_34/DM-26441/remainder'],dataId=did)\n",
    "\n",
    "        for i in range(len(metricnames)):\n",
    "            metric = metricnames[i]\n",
    "            dataset = f\"metricvalue_validate_drp_{metric}\"\n",
    "    \n",
    "            query = registry.queryDatasets(datasetType=dataset, collections=[collectionName], dataId=did)\n",
    "            for meas in query:            \n",
    "                metric_tmp = butler_gen3.get(meas, collections=[collectionName])\n",
    "                metric_agg_vals[p,i]=metric_tmp.quantity.value\n",
    "\n",
    "                if i == 0:\n",
    "                #try:\n",
    "                    #coadd = butler_gen3.get('deepCoadd_calexp', collections=['RC2/w_2020_34/DM-26441/remainder'],dataId=did)\n",
    "                    wcs = coadd.getWcs()\n",
    "                    xy0 = wcs.pixelToSky(geom.Point2D(coadd.getXY0()))\n",
    "                    metric_ra.append(xy0.getRa().asDegrees())\n",
    "                    metric_dec.append(xy0.getDec().asDegrees())\n",
    "                \n",
    "            #metric_agg_tmp = np.array(metric_agg_tmp)\n",
    "            #metric_agg_vals.append(metric_agg_tmp)\n",
    "    except:\n",
    "        #metric_agg_tmp = np.zeros(len(metricnames))\n",
    "        #metric_agg_tmp[:] = np.nan\n",
    "        #metric_agg_vals[p,:] = metric_agg_tmp\n",
    "        metric_ra.append(999.9999)\n",
    "        metric_dec.append(999.9999)\n",
    "        print('Patch ',p,' not found. Skipping.')\n",
    "\n",
    "    \n",
    "tab_metrics_perpatch_all = Table([metric_patch, metric_ra, metric_dec, metric_agg_vals],\n",
    "                                 names=('patch', 'ra', 'dec', 'metrics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_vals[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':8}\n",
    "#print(did)\n",
    "#butler_gen3.datasetExists('deepCoadd_calexp', collections=['RC2/w_2020_34/DM-26441/remainder'], dataId=did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the ones with no data:\n",
    "\n",
    "tab_metrics_perpatch = tab_metrics_perpatch_all[tab_metrics_perpatch_all['ra'] < 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_metrics_perpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "   'axes.labelsize': 28,\n",
    "   'font.size': 24,\n",
    "   'legend.fontsize': 14,\n",
    "   'xtick.major.width': 3,\n",
    "   'xtick.minor.width': 2,\n",
    "   'xtick.major.size': 12,\n",
    "   'xtick.minor.size': 6,\n",
    "   'xtick.direction': 'in',\n",
    "   'xtick.top': True,\n",
    "   'lines.linewidth':3,\n",
    "   'axes.linewidth':3,\n",
    "   'axes.labelweight':3,\n",
    "   'axes.titleweight':3,\n",
    "   'ytick.major.width':3,\n",
    "   'ytick.minor.width':2,\n",
    "   'ytick.major.size': 12,\n",
    "   'ytick.minor.size': 6,\n",
    "   'ytick.direction': 'in',\n",
    "   'ytick.right': True,\n",
    "   'figure.figsize': [10, 8]\n",
    "   }\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "metric_to_plot = metricnames[0] #'PA1' # set this to any of the metrics in \"metricnames\"\n",
    "find_metric_name = np.where(np.char.find(metricnames, metric_to_plot) >= 0)\n",
    "\n",
    "plt.scatter(tab_metrics_perpatch['ra'], tab_metrics_perpatch['dec'], c=tab_metrics_perpatch['metrics'][:,find_metric_name], \n",
    "            cmap='rainbow', s=60)\n",
    "#plt.xlim(216.4,216.1)\n",
    "#plt.ylim(0.742,0.746)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(r'RA (deg)')\n",
    "plt.ylabel(r'Dec (deg)')\n",
    "plt.minorticks_on()\n",
    "plt.colorbar(label=metricnames[find_metric_name[0][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the actual matched catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"matchedCatalog\"\n",
    "patch = 3\n",
    "did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':patch}\n",
    "mch_cat = butler_gen3.get(dataset, dataId=did, collections=[collectionName])\n",
    "metric_tmp3 = butler_gen3.get('metricvalue_validate_drp_PA1', dataId=did, collections=[collectionName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = np.unique(mch_cat['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_arr = []\n",
    "\n",
    "for obj in objs:\n",
    "    pickobj = (mch_cat['object'] == obj) & (mch_cat['base_ClassificationExtendedness_value'] < 0.5) &\\\n",
    "              (mch_cat['base_PsfFlux_snr'] > 50.0) & (mch_cat['base_PixelFlags_flag_saturated'] == False) &\\\n",
    "              (mch_cat['base_PixelFlags_flag_cr'] == False) & (mch_cat['base_PixelFlags_flag_bad'] == False) &\\\n",
    "              (mch_cat['base_PixelFlags_flag_edge'] == False)\n",
    "    if len(mch_cat[pickobj]) > 1:\n",
    "        mags_tmp = mch_cat[pickobj]['base_PsfFlux_mag']\n",
    "        # mch_cat[pickobj]['base_ClassificationExtendedness_value']\n",
    "        diffs = mags_tmp - np.mean(mags_tmp)\n",
    "        rms = np.sqrt(np.mean((diffs)**2))*1000.0\n",
    "        rms_arr.append(rms)\n",
    "#        diffs = mch_cat[pickobj[0]]['base_PsfFlux_mag'] - mch_cat[pickobj]['base_PsfFlux_mag']\n",
    "        print(rms, len(diffs), mch_cat[pickobj]['base_PsfFlux_mag'])\n",
    "\n",
    "print('median: ',np.median(rms_arr),' Meas: ',metric_tmp3)\n",
    "#        print(np.sqrt(np.mean((diffs-np.mean(diffs))**2))*1000.0, len(diffs), np.mean(diffs), mch_cat[pickobj]['base_PsfFlux_mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rms_arr, bins=np.arange(0, 50, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure PA1 directly for all patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set the RA, Dec for patches with no data to 999.999. Filter those out:\n",
    "filt = np.where(tab_metrics_perpatch_all['ra'] < 400)\n",
    "patches_tmp = np.array(metric_patch)\n",
    "patches = patches_tmp[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_RMS(x):\n",
    "    return np.sqrt(np.mean((x-np.mean(x))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"matchedCatalog\"\n",
    "\n",
    "pa1_direct = []\n",
    "pa1_mpt = []\n",
    "nstars_patch = []\n",
    "magdiffs_all = []\n",
    "\n",
    "for patch in patches:\n",
    "    print('patch: ',patch)\n",
    "    did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':patch}\n",
    "    mch_cat_tmp = butler_gen3.get(dataset, dataId=did, collections=[collectionName])\n",
    "    mch_cat1 = mch_cat_tmp.copy(deep=True)\n",
    "    qual_cuts = (mch_cat1['base_ClassificationExtendedness_value'] < 0.5) &\\\n",
    "                (mch_cat1['base_PsfFlux_snr'] > 50.0) & (mch_cat1['base_PixelFlags_flag_saturated'] == False) &\\\n",
    "                (mch_cat1['base_PixelFlags_flag_cr'] == False) & (mch_cat1['base_PixelFlags_flag_bad'] == False) &\\\n",
    "                (mch_cat1['base_PixelFlags_flag_edge'] == False)\n",
    "    mch2 = mch_cat1[qual_cuts].copy(deep=True).asAstropy()\n",
    "    mch_cat = mch2.to_pandas()    \n",
    "    metric_tmp3 = butler_gen3.get('metricvalue_validate_drp_PA1', dataId=did, collections=[collectionName])\n",
    "\n",
    "    rms_arr = []\n",
    "    # count = 0\n",
    "\n",
    "    mch_cat_agg = mch_cat.groupby('object').agg({'base_PsfFlux_mag':['mean',cal_RMS,'count']})\n",
    "    ok_agg = (mch_cat_agg.base_PsfFlux_mag['count'] > 1)\n",
    "    rms_arr.append(1000.0*mch_cat_agg.base_PsfFlux_mag['cal_RMS'][ok_agg])\n",
    "    nstars_patch.append(len(mch_cat_agg.base_PsfFlux_mag['cal_RMS'][ok_agg]))\n",
    "\n",
    "    pa1_direct.append(np.median(rms_arr))\n",
    "    pa1_mpt.append(metric_tmp3.quantity.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_compare = Table([patches, pa1_direct, pa1_mpt, nstars_patch],\\\n",
    "                    names=('patch', 'PA1_direct', 'PA1_MPT', 'nstars_patch'), dtype=(int, 'f2', 'f2', int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_compare.write('RC2_tract9813_PA1_compare.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tab_compare['nstars_patch'],\\\n",
    "            100.0*(tab_compare['PA1_direct']-tab_compare['PA1_MPT'])/tab_compare['PA1_direct'],\\\n",
    "            c=tab_compare['PA1_MPT'], s=50, cmap='gist_rainbow')\n",
    "plt.xlabel(r'N$_{\\rm stars}$')\n",
    "plt.ylabel('Percent difference')\n",
    "plt.hlines(0,0,300,linestyle='--')\n",
    "plt.xlim(0,140)\n",
    "plt.colorbar(label='PA1_MPT (mmag)')\n",
    "plt.minorticks_on()\n",
    "plt.savefig('PA1_comp_RC2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tab_compare['PA1_direct'], bins=np.arange(0,50,2), color='Red', label='direct measurement', histtype='step', linewidth=4)\n",
    "plt.hist(tab_compare['PA1_MPT'], bins=np.arange(0,50,2), color='Black', linestyle='--', label='metrics-pipeline-task', histtype='step', linewidth=4)\n",
    "plt.vlines(np.nanmedian(tab_compare['PA1_direct']),0,17,linestyle=':',color='Red',label='median: '+str(np.nanmedian(tab_compare['PA1_direct'])))\n",
    "plt.vlines(np.nanmedian(tab_compare['PA1_MPT']),0,17,linestyle=':',color='Black',label='median: '+str(np.nanmedian(tab_compare['PA1_MPT'])))\n",
    "plt.xlabel('PA1 (mmag)')\n",
    "plt.ylabel('N')\n",
    "plt.ylim(0,15)\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.savefig('PA1_comp_RC2_tract9813_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.afw.table import GroupView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = \"matchedCatalog\"\n",
    "\n",
    "#mch_cat_tmp = []\n",
    "\n",
    "count=0\n",
    "for p in patches[68:70]:\n",
    "\n",
    "    did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':p}\n",
    "    mch_cat_tmp0 = butler_gen3.get(dataset3, dataId=did, collections=[collectionName])\n",
    "    if count==0:\n",
    "        mch_cat_tmp = mch_cat_tmp0.copy()\n",
    "    else:\n",
    "        mch_cat_tmp.append(mch_cat_tmp0)\n",
    "\n",
    "gv = GroupView.build(mch_cat_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_cuts = (mch_cat_tmp['base_ClassificationExtendedness_value'] < 0.5) &\\\n",
    "            (mch_cat_tmp['base_PsfFlux_snr'] > 50.0) & (mch_cat_tmp['base_PixelFlags_flag_saturated'] == False) &\\\n",
    "            (mch_cat_tmp['base_PixelFlags_flag_cr'] == False) & (mch_cat_tmp['base_PixelFlags_flag_bad'] == False) &\\\n",
    "            (mch_cat_tmp['base_PixelFlags_flag_edge'] == False)\n",
    "\n",
    "mch_cat = mch_cat_tmp[qual_cuts].copy(deep=True)\n",
    "gv = GroupView.build(mch_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gv.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.validate.drp import repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magkey = gv.schema.find('base_PsfFlux_mag').key\n",
    "#print(magkey)\n",
    "#repeatability.measurePhotRepeat('PA1','HSC-R', matches=gv, magKey=magkey)\n",
    "\n",
    "def matchFilter(cat):\n",
    "    if len(cat) < 2:\n",
    "        return False\n",
    "    return np.isfinite(cat.get(magkey)).all()\n",
    "\n",
    "#repeat = repeatability.calcPhotRepeat(gv.where(matchFilter), magkey)\n",
    "repeat = repeatability.measurePhotRepeat('PA1','HSC-R', matches=gv.where(matchFilter), magKey=magkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = \"matchedCatalog\"\n",
    "\n",
    "mch_cat_repeat = []\n",
    "\n",
    "def matchFilter(cat):\n",
    "    if len(cat) < 2:\n",
    "        return False\n",
    "    return np.isfinite(cat.get(magkey)).all()\n",
    "\n",
    "for p in patches:\n",
    "\n",
    "    did={'tract':9813, 'abstract_filter':'r', 'instrument':'HSC', 'skymap':'hsc_rings_v1', 'patch':p}\n",
    "    mch_cat_tmp = butler_gen3.get(dataset3, dataId=did, collections=[collectionName])\n",
    "\n",
    "    qual_cuts = (mch_cat_tmp['base_ClassificationExtendedness_value'] < 0.5) &\\\n",
    "                (mch_cat_tmp['base_PsfFlux_snr'] > 50.0) & (mch_cat_tmp['base_PixelFlags_flag_saturated'] == False) &\\\n",
    "                (mch_cat_tmp['base_PixelFlags_flag_cr'] == False) & (mch_cat_tmp['base_PixelFlags_flag_bad'] == False) &\\\n",
    "                (mch_cat_tmp['base_PixelFlags_flag_edge'] == False)\n",
    "\n",
    "    mch_cat = mch_cat_tmp[qual_cuts].copy(deep=True)\n",
    "    gv = GroupView.build(mch_cat)\n",
    "    \n",
    "    if len(gv.where(matchFilter)) > 10:\n",
    "        magkey = gv.schema.find('base_PsfFlux_mag').key\n",
    "        repeat = repeatability.measurePhotRepeat('PA1','HSC-R', matches=gv.where(matchFilter), magKey=magkey)\n",
    "    \n",
    "        mch_cat_repeat.append(repeat.quantity.value)\n",
    "    else:\n",
    "        mch_cat_repeat.append(np.nan)\n",
    "\n",
    "        \n",
    "mch_cat_repeat = np.array(mch_cat_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(np.where(mch_cat_tmp['base_ClassificationExtendedness_value'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tab_compare['nstars_patch'],\\\n",
    "            100.0*(tab_compare['PA1_direct']-mch_cat_repeat)/mch_cat_repeat,\\\n",
    "            c=tab_compare['PA1_MPT'], s=50, cmap='gist_rainbow')\n",
    "plt.xlabel(r'N$_{\\rm stars}$')\n",
    "plt.ylabel('Percent difference')\n",
    "plt.hlines(0,0,300,linestyle='--')\n",
    "plt.xlim(0,140)\n",
    "plt.colorbar(label='PA1_validate_drp (mmag)')\n",
    "plt.minorticks_on()\n",
    "plt.savefig('PA1_comp_RC2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tab_compare['PA1_direct'], bins=np.arange(0,50,2), color='Red', label='direct measurement', histtype='step', linewidth=4)\n",
    "plt.hist(tab_compare['PA1_MPT'], bins=np.arange(0,50,2), color='Black', linestyle='--', label='metrics-pipeline-task', histtype='step', linewidth=4)\n",
    "plt.hist(mch_cat_repeat, bins=np.arange(0,50,2), color='DodgerBlue', linestyle='-.', label='validate_drp', histtype='step', linewidth=4)\n",
    "plt.vlines(np.nanmedian(tab_compare['PA1_direct']),0,18,linestyle=':',color='Red',label='median: '+str(np.nanmedian(tab_compare['PA1_direct'])))\n",
    "plt.vlines(np.nanmedian(tab_compare['PA1_MPT']),0,18,linestyle=':',color='Black',label='median: '+str(np.nanmedian(tab_compare['PA1_MPT'])))\n",
    "plt.vlines(np.nanmedian(mch_cat_repeat),0,18,linestyle=':',color='DodgerBlue',label='median: '+str(np.nanmedian(mch_cat_repeat)))\n",
    "plt.xlabel('PA1 (mmag)')\n",
    "plt.ylabel('N')\n",
    "plt.ylim(0,18)\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.savefig('PA1_comp_RC2_tract9813_hist_withValidateDrp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
